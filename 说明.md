### 项目结构

```
<root>
│   emotic_keras_training.py
│   emotic_keras_glove.py
│   emotic_keras_test.py
│   tools.py
│   ...
└───data
│   │   generate_corpus.py
│   │   speech_to_text.py
│   └── corpus
│   │   │   source.txt
│   │   │   <corpus>
│   │   
│   └───models
│       │   output_graph.pbmm
│       │   alphabet.txt
│       │   ...
│   
└───glove
    │   glove.6B.100d.txt
```

根目录下为主要的训练及预测代码，其中`emotic_keras_training.py`、`emotic_keras_glove.py`为模型训练代码，`emotic_keras_test.py`为使用已训练模型的代码，`tools.py`包含一些工具函数。

在`data/`文件夹中放置原始数据集及数据集预处理代码。数据集通过`speech_to_text.py`进行语音转文字，通过`generate_corpus.py`进行数据集的预处理。`corpus`文件夹中放置原始数据集，`source.txt`记录不同数据集的来源。特别地，`models/`文件夹中为一些DeepSpeech工具的模型，获取方法为：

```
wget https://github.com/mozilla/DeepSpeech/releases/download/v0.5.1/deepspeech-0.5.1-models.tar.gz
tar xvfz deepspeech-0.5.1-models.tar.gz
```

`glove/`文件夹中的为预训练的GloVe模型。其获取链接为`http://nlp.stanford.edu/data/glove.6B.zip`，本实验使用了压缩包中的`glove.6B.100d.txt`进行实验。

---

### 环境及工具

* Windows >= 7
* Python > 3.4
* pip >= 19.0
* tensorflow 2.x
* keras 2.x

---

### 环境的搭建

建议使用anaconda进行实验。anaconda的安装包从[官网下载](https://www.anaconda.com/distribution/#download-section)，下载Python 3.x的版本。按照提示进行安装。安装完成后，打开Anaconda Prompt，创建一个名为`py36`的python版本为3.x的conda运行环境并激活该环境（[安装参考](https://zhuanlan.zhihu.com/p/36398337)）：

```
conda create --name py36 python=3.6
activate py36
```

接下来是Kera环境的搭建（[搭建参考](https://zhuanlan.zhihu.com/p/36551413)），安装Tensorflow

```
conda install tensorflow
```

安装Keras

```
pip install keras
```

安装完成后，进入Python，尝试载入Keras，无报错即安装成功：

```
# python
import keras
```

---

### 数据集预处理

#### 语音转文字工具DeepSpeech

由于没有找到非常合适的语音数据集，因此这一步不是必须的。

安装DeepSpeech库

```
pip install deepspeech
```

语音转文字

```
python speech_to_text.py --model ./models/output_graph.pbmm --alphabet ./models/alphabet.txt --audio path/of/audio
```

#### 生成训练集和测试集 (generate_corpus.py)

文件中`path_corpus_original`为原始数据集的路径，`path_train_corpus`和`path_test_corpus`分别为基于原始数据集进行处理后生成的训练数据集和测试数据集的路径及名称。

本实验中，将`data/corpus/tlkh.txt`放到`data/`下，并重命名为`text_emotion_original.txt`，直接运行文件：

```
python generate_corpus.py
```

生成两个文件`train.txt`和`test.txt`，分别为训练集和测试集。

---

### 神经网络训练

文件`emotic_keras_training.py`为使用one-hot和Skip-gram方法进行词嵌入实验的代码，而文件`emotic_keras_glove.py`为使用GloVe进行词嵌入的实验代码。

在`emotic_keras_training.py`中，通过修改`input_struct`选择不同的词嵌入方法，`'bag_of_words'`为one-hot方法，`'sequence_of_words'`为Skip-gram方法。

修改`epochs`改变训练的迭代次数。

通过修改`model_type`对神经网络的结构进行修改，它的值可为`'feed_forward','rnn','lstm','bi_lstm','cnn','cnn_lstm'`，但当`input_struct`（词嵌入方法）为`'sequence_of_words'`，只能选择`'rnn','lstm','bi_lstm'`作为`model_type`的值，因为只有循环神经网络支持序列式输入。

除此之外，可以通过直接修改`# definition of the model`模块使用预设神经层进行网络构造。（也可以自定义层的结构，参考[编写你自己的Keras层](https://keras.io/zh/layers/writing-your-own-keras-layers/)。修改变量`path_train_txt`和`path_test_txt`从而指向训练集及测试集。

运行`emotic_keras_training.py`：

```
python emotic_keras_training.py
```

同理，在`emotic_keras_glove.py`中，通过修改`# definition of the model`部分可对神经网络的结构进行修改，修改变量`path_train_txt`和`path_test_txt`从而指向训练集及测试集。修改`epochs`改变训练的迭代次数。

运行`emotic_keras_glove.py`：

```
python emotic_keras_glove.py
```

---

### 使用已训练模型进行单句情感预测

使用`emotic_keras_test.py`使用已训练模型进行预测，修改`phrase`变量改变需要预测的句子。

文件中的`# prediction with the model`部分划分为四个部分，分别对应：

1. 使用`emotic_keras_training.py`进行训练，并且`input_struct`的值为`'bag_of_words'`，`model_type`的值**不**为`'rnn','lstm'或'bi_lstm'`
2. 使用`emotic_keras_training.py`进行训练，并且`input_struct`的值为`'bag_of_words'`，`model_type`的值为`'cnn','rnn','lstm'或'bi_lstm'`
3. 使用`emotic_keras_training.py`进行训练，并且`input_struct`的值为`'bag_of_words'`，`model_type`的值为`'cnn_lstm'`
4. 使用`emotic_keras_training.py`进行训练，并且`sequence_of_words`的值为`'bag_of_words'`，`model_type`的值为`'rnn','lstm'或'bi_lstm'`
5. 使用`emotic_keras_glove.py`进行训练

根据不同的训练方法，将文件中的对应部分取消注释，并将其他非对应的训练方法部分的代码设为注释，然后运行`emotic_keras_test.py`，获得预测结果：

```
python emotic_keras_test.py
```
